import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
%pylab inline
import seaborn as sns
from pandas import read_csv
from matplotlib import pyplot

# Load data 
Twitter_Train = pd.read_csv("/Users/shimonyagrawal/Desktop/Social Media Analytics/train.csv")
Twitter_Train 

Twitter_Train.info()

Twitter_Train.describe()

print("Any missing values in the dataset:", Twitter_Train.isnull().values.any())

# Testing the correlation 

correlationA = Twitter_Train .iloc[:,1:12].corr(method = 'pearson')
correlationA

ax = sns.heatmap( 
    correlationA, 
    vmin=-1, vmax=1, center=0, 
    cmap=sns.diverging_palette(20, 220, n = 200),
    square=True,
)
ax.set_xticklabels(  
    ax.get_xticklabels(), 
    rotation=45, 
    horizontalalignment='right'
)

correlationB = Twitter_Train.iloc[:,12:23].corr(method='pearson')
correlationB

ax = sns.heatmap(
    correlationB, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n = 200),
    square=True,
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
)

# To prepare the dataset for machine learning models, the dataset is divided into Test data and Train data. By creating a train and test split of your dataset helps in quickly evaluating the performance of an algorithm on your problem. The training dataset is used to prepare a model, to train it and the test dataset is new data where the output values are withheld from the algorithm. Transforming A and B individuals into A-B variables for better interpretation of the model.For the test data, values are selected from the data. For the train data, one variable is chosen to build the model. Here, the model is built upon the variable "choice". 

x = pd.DataFrame(Twitter_Train.iloc[:,1:10].values - Twitter_Train.iloc[:,10:19].values)
x.columns = ['A/B_follower_count','A/B_following_count','A/B_listed_count','A/B_retweets_received',
             'A/B_mentions_sent','A/B_retweets_sent','A/B_posts','A/B_network_feature_2','A/B_network_feature_3']
y= Twitter_Train['Choice']
# The train_test_split function is for splitting a single dataset for two different purposes: training and testing. The testing subset is for building your model. The testing subset is for using the model on unknown data to evaluate the performance of the model.

from sklearn.model_selection import train_test_split

x_train , x_test, y_train, y_test = train_test_split (x, y, test_size = 0.30, random_state = 42)
# Looking at the shape of the data to test whether training features number of columns match testing feature number of columns.The number of rows to match for the respective training and testing features and the labels

print('X_Train Shape:', x_train.shape)
print('Y_Train Shape:', y_train.shape)
print('X_Test Shape:', x_test.shape)
print('Y_Test Shape:', y_test.shape)

# Spot Check Algorithms

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold


models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(("RF", RandomForestClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
models.append(('Xgboost', XGBClassifier()))

# evaluate each model in turn
results = []
names = []
for name, model in models:
    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_results = cross_val_score(model, x_train, y_train, cv = kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))

# Logtistic Regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.feature_selection import RFE
 

model_logreg = LogisticRegression()
rfe = RFE(model_logreg, 9)
rfe = rfe.fit(x_train, y_train.values.ravel())
print(rfe.support_)  #Indicates all variables have been selected by RFE with a ranking of 1 
print(rfe.ranking_)   

import statsmodels.api as sm

logit_model = sm.Logit(y,x)
result = logit_model.fit()
print(result.summary2())

# Removing variables with p-values greater than 0.05 to improve the model 

columns_to_keep = ['A/B_follower_count', 'A/B_retweets_received', 'A/B_mentions_sent', 
                   'A/B_network_feature_2', 'A/B_network_feature_3']
x = x_train[columns_to_keep]
y = y_train 

logit_model = sm.Logit(y,x)
result = logit_model.fit()
print(result.summary2())

# Logistic Regression Model Fitting 

model_logreg.fit(x_train, y_train)

# Predicting test results 

y_pred = model_logreg.predict(x_test)
# Calculating the accuracy of our model 

print("Training accuracy of Logistic Regression model:", model_logreg.score(x_train, y_train))
print("Testing accuracy of Logistic Regression model:", model_logreg.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix (y_test,y_pred)
print(confusion_matrix).

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred))

# Random Forest Classifier 

from sklearn.ensemble import RandomForestClassifier

model_rf = RandomForestClassifier()
model_rf.fit(x_train, y_train) #Train the model on training data 

# Predicting the test results 
  
y_pred = model_rf.predict(x_test)
# Calculating the accuracy of our model  

print("Training accuracy of Random Forest model:", model_rf.score(x_train, y_train))
print("Testing accuracy of Random Forest model:", model_rf.score(x_test, y_test))

# To interpret the model and report the results, feature importances is used to quantify how much a particular variable improves predctions 

feature_importances = pd.DataFrame(model_rf.feature_importances_,
                          index = x_train.columns, 
                          columns = ['importance']).sort_values('importance', ascending = False)
feature_importances

# Select features with importance larger than 0.08 

columns_to_keep = ['A/B_mentions_sent', 'A/B_listed_count', 'A/B_follower_count', 
                   'A/B_network_feature_3', 'A/B_retweets_sent', 'A/B_posts']

x = x_train[columns_to_keep]
y = y_train 

model_rf = RandomForestClassifier() #New random forest classifier for the most important features 
model_rf.fit(x_train, y_train) #Train the model on training data 

# Predicting the test results 

y_pred = model_rf.predict(x_test)
# Calculating the accuracy of the model 

print("Training accuracy of Random Forest model:", model_rf.score(x_train, y_train))
print("Testing accuracy of Random Forest model:", model_rf.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

conf_matrix = confusion_matrix (y_test,y_pred)
print(conf_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred))

# K-Nearest Neighbors

from sklearn.neighbors import KNeighborsClassifier

model_knn = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')
model_knn.fit(x_train, y_train)

y_pred = model_knn.predict(x_test)
# Calculating training and testing of our model

print("Training accuracy of K-Nearest Neighbors model:", model_knn.score(x_train, y_train))
print("Testing accuracy of K-Nearest Neighbors model:", model_knn.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred))

# XGBoost Classifier 

from xgboost import XGBClassifier
from xgboost import plot_importance

model_xgb = XGBClassifier(max_depth = 2, 
                          objective = 'binary:logistic',
                          eta = 0.3
                         )
model_xgb

model_xgb.fit(x_train, y_train)
print(model_xgb)

y_pred = model_xgb.predict(x_test)

# Calculating training and testing of our model

print("Training accuracy of XGBoost model:", model_xgb.score(x_train, y_train))
print("Testing accuracy of XGBoost model:", model_xgb.score(x_test, y_test))


plot_importance(model_xgb, max_num_features=9)
pyplot.show()

# Select the top 5 features and re-run the model 

from sklearn.metrics import confusion_matrix, classification_report

cols = ['A/B_follower_count','A/B_network_feature_3','A/B_listed_count',  
        'A/B_network_feature_2','A/B_retweets_received' ]
x = x_train[cols]
y = y_train 


model_xgb = XGBClassifier() #New xgb classifier for the most important features 
model_xgb.fit(x_train, y_train) #Train the model on training data 

#Predicting the test results

y_pred = model_xgb.predict(x_test)

plot_importance(model_xgb, max_num_features=5)
pyplot.show()

# Calculating the accuracy of the model 

print("Training accuracy of XGBoost model:", model_xgb.score(x_train, y_train))
print("Testing accuracy of XGBoost model:", model_xgb.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred))

